{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.activate(joinpath(@__DIR__,\"..\")); Pkg.instantiate()\n",
    "using ForwardDiff\n",
    "using Test\n",
    "using RobotZoo\n",
    "import RobotDynamics\n",
    "using LinearAlgebra\n",
    "using StaticArrays\n",
    "using SparseArrays\n",
    "using Printf\n",
    "using MeshCat\n",
    "using Plots\n",
    "using FiniteDiff\n",
    "import MathOptInterface as MOI\n",
    "using Ipopt\n",
    "using JLD2\n",
    "\n",
    "include(\"quadratic_cost.jl\")   # defines the quadratic cost function type\n",
    "include(\"q2_model.jl\")         # sets up the dynamics\n",
    "const isautograder = @isdefined autograder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Sequential Quadratic Programming (SQP) (50 pts)\n",
    "In this problem you'll solve the canonical cartpole swing-up problem using the classic direct collocation algorithm with Hermite-Simpson integration. \n",
    "\n",
    "### Continuous Problem\n",
    "We will be solving a trajectory optimization problem of the form:\n",
    "$$\n",
    "\\begin{aligned} \n",
    "&\\underset{x(t), u(t)}{\\text{minimize}} && J_f(x(t_f)) + \\int_{t_0}^{t_f} J(x(t), u(t)) dt \\\\\n",
    "&\\text{subject to} && \\dot{x}(t) = f(x(t), u(t), t) \\\\\n",
    "&&& x(t_0) = x_\\text{init} \\\\\n",
    "&&& x(t_f) = x_\\text{goal}\n",
    "\\end{aligned} \n",
    "$$\n",
    "\n",
    "### Hermite-Simpson Collocation\n",
    "Recall from lecture that direct collocation \"transcribes\" the continuous-time optimal control problem into a finite-dimensional nonlinear program (NLP). We will use Hermite-Simpson integration on both our dynamics and our cost function. We will split our \n",
    "cost integral into $N-1$ segments of length $h$ seconds, and approximate the cost \n",
    "over this interval using a Hermite spline:\n",
    "\n",
    "$$ \\int_{t_k}^{t_{k+1}} J\\big(x(t),u(t)\\big) dt \\approx \n",
    "\\frac{h}{6}\\bigg(\n",
    "J\\big(x(t_k), u(t_k)\\big) + \n",
    "4 J\\big(x(t_k + h/2), u(t_k + h/2)\\big) + \n",
    "J\\big(x(t_k + h), u(t_k + h)\\big) \\bigg) $$\n",
    "\n",
    "where we calculate the state at the midpoint with:\n",
    "$$ x(t_k + h/2) = x_m = \\frac{1}{2} \\big(x_1 + x_2 \\big) + \n",
    "\\frac{h}{8}\\big(f(x_k, u_k, t_k) - f(x_{k+1}, u_{k+1}, t_{k+1}) \\big) $$\n",
    "\n",
    "and we use first-order-hold on the controls:\n",
    "$$ u(t_k + h/2) = u_m = \\frac{1}{2} \\big( u_1 + u_2 \\big) $$\n",
    "\n",
    "For our dynamics constraint, we use implicit integration with the same Hermite spline:\n",
    "$$ \\frac{h}{6} \\big(f(x_k,u_k,t_k) + 4f(x_m,u_m,t_m) + f(x_{k+1}, u_{k+1}, t_{k+1}) \\big) + x_k - x_{k+1} = 0 $$\n",
    "\n",
    "### Discrete Problem\n",
    "The resulting NLP has the following form:\n",
    "$$\n",
    "\\begin{aligned} \n",
    "&\\underset{x_{1:N}, u_{1:N}}{\\text{minimize}} && J_f(x_N) + \n",
    "\\sum_{k=1}^{N-1} \\frac{h}{6}(J(x_k,u_k) + 4J(x_m,u_m) + J(x_{k+1}, u_{k+1}))  \\\\\n",
    "&\\text{subject to} && \\frac{h}{6} \\big(f(x_k,u_k,t_k) + 4f(x_m,u_m,t_m) + f(x_{k+1}, u_{k+1}, t_{k+1}) \\big) + x_k - x_{k+1} = 0 \\\\\n",
    "&&& x_1 = x_\\text{init} \\\\\n",
    "&&& x_N = x_\\text{goal}\n",
    "\\end{aligned} \n",
    "$$\n",
    "\n",
    "Note that the state midpoint is really a function of the states and controls at the surrounding knot points: $x_m(x_k, u_k, x_{k+1}, u_{k+1}, t_k, h)$ and the control at the midpoint is a function of the previous and next and control values: $u_m(u_k, u_{k+1})$. You will need differentiate through these splines using the chain rule to generate the methods we need to solve our NLP.\n",
    "\n",
    "### Solving the Problem\n",
    "To make things easier, we'll use Ipopt to solve our NLP, but you'll still need to define the functions we pass to Ipopt. Ipopt expects a problem of the following form:\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "&\\underset{x}{\\text{minimize}} && f(x) \\\\\n",
    "&\\text{subject to} && l \\leq c(x) \\leq u\\\\\n",
    "\\end{aligned} \n",
    "$$\n",
    "\n",
    "Since our problem only has equality constraints, our upper and lower bounds $u$ and $l$ will both be zero. Ipopt requires that we specify analytical functions that evaluate $\\nabla f$ and $\\nabla c$. For best performance, the function evaluating the constraint Jacobian typically only evaluates the nonzero elements. To make things simple, we treat the Jacobian as dense. \n",
    "\n",
    "This homework problem will give you valuable experience in setting up the optimization problems in a way that can be passed to off-the-shelf NLP solvers like Ipopt.\n",
    "\n",
    "## The Problem\n",
    "You likely have already seen the cartpole swing-up problem previously.The system is comprised of a pendulum attached to a cart, where forces can only be applied to the cart. The goal is to balance the pendulum above the cart. The system dynamics can be written as:\n",
    "\n",
    "$$ x = \\begin{bmatrix} y \\\\ \\theta \\\\ v \\\\ \\omega \\end{bmatrix}, \\quad \\dot{x} = \\begin{bmatrix} \\dot{q} \\\\ \\ddot{q} \\end{bmatrix}, \\quad\n",
    "q = \\begin{bmatrix} y \\\\ \\theta \\end{bmatrix}, \\quad\n",
    "\\ddot{q} = -H^{-1} (C \\dot{q} + G - B u)$$\n",
    "\n",
    "where \n",
    "$$ H = \\begin{bmatrix} m_c + m_p & m_p l \\cos{\\theta} \\\\\n",
    "m_p l \\cos{\\theta} & m_p l^2 \\end{bmatrix}, \\;\n",
    "C = \\begin{bmatrix} 0 & -m_p \\omega l \\sin{\\theta} \\\\ 0 & 0 \\end{bmatrix}, \\;\n",
    "G = \\begin{bmatrix} 0 \\\\ m_p g l \\sin{\\theta} \\end{bmatrix}, \\;\n",
    "B = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} $$\n",
    "\n",
    "with the following parameters:\n",
    "* $m_p$: mass of the pole\n",
    "* $m_c$: mass of the cart\n",
    "* $g$: gravity\n",
    "* $l$: length of the rod\n",
    "\n",
    "Our goal is to move the cart in a way that we get the pendulum to swing from the downward position (`[0,0,0,0]`) to an upright position (`[0,pi,0,0]`).\n",
    "\n",
    "We've encapsulated all of the problem information into a `struct` for convenience (and to avoid polluting our global workspace with uncessary global variables). \n",
    "\n",
    "\n",
    "## Developing in External Editor\n",
    "All of the methods you need to implement in this problem are in external Julia files.\n",
    "Feel free to use a text editor / IDE of your choice (the Julia VSCode extension is the IDE recommended by the Julia community) to write and test these methods. You can use the `q2.jl` script to run the code, which includes tests that are identical to those in this notebook. We will be running the notebooks for for the autograder, so before you submit make sure this notebook runs as expected and passes the tests (or run `test/runtests.jl` which will run the autograder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"q2_prob.jl\")  # Defines a struct containing all of the problem information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = CartpoleProblem();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let model = prob.model\n",
    "    isautograder && return\n",
    "    global vis = Visualizer()\n",
    "    set_mesh!(vis, model)\n",
    "    render(vis)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let X = get_initial_trajectory(prob)[1]\n",
    "    isautograder || visualize!(vis, prob.model, prob.tf, X)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a): Write Cost Functions (15 pts)\n",
    "Our first task will be to write methods to evaluate our objective / cost function. We first create a `struct` that will be responsible for evaluating all the functions we need to pass to Ipopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"q2_nlp.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Examples\n",
    "You may find the following code snippets helpful as you complete the methods for the NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    # Create NLP\n",
    "    nlp = NLP(prob)\n",
    "\n",
    "    # Create a vector of all states and controls\n",
    "    X,U = get_initial_trajectory(prob)\n",
    "    Z = packZ(nlp, X, U)\n",
    "\n",
    "    # Unpack into states and vectors\n",
    "    X2, U2 = unpackZ(nlp, Z)\n",
    "\n",
    "    # Get kth state, control\n",
    "    k = 10\n",
    "    x = Z[nlp.xinds[k]]\n",
    "    u = Z[nlp.uinds[k]]\n",
    "\n",
    "    # Dynamics\n",
    "    t = nlp.times[k]\n",
    "    dt = nlp.times[k+1] - nlp.times[k]\n",
    "    dynamics(nlp.model, x, u, t)\n",
    "\n",
    "    # Dynamics Jacobian\n",
    "    A,B = dynamics_jacobians(nlp.model, x, u, t);\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "**TASK** Finish the following methods defined in this file included in the cell below:\n",
    "- `eval_f` (5 pts)\n",
    "- `grad_f!` (10 pts)\n",
    "\n",
    "The docstrings for these function are printed below. You will be graded on the number of function and Jacobian evaluations you use. You should avoid unnecessary dynamics and dynamics Jacobian evaluations. You should only need a maximum `N + (N-1)` evaluations each of the dynamics and dynamics Jacobians for each function.\n",
    "\n",
    "**TIP**: You may find it helpful to define some helper function that evaluate all of the terms you need upfront. We've provided some example starter code in `q2_dynamics.jl`. Feel free to include that file and modify as needed. You can also add fields to the `NLP` struct if you feel the need (the TA's solution uses the provided fields)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"q2_cost_methods.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?eval_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?grad_f!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"Q2a\" begin                                               # POINTS = 15\n",
    "    prob = CartpoleProblem()\n",
    "    nlp = NLP(prob)\n",
    "    X,U = get_initial_trajectory(prob) \n",
    "    Z = packZ(nlp, X, U)\n",
    "\n",
    "    @testset \"eval_f\" begin                                        # POINTS = 5\n",
    "        # Test the cost\n",
    "        @test eval_f(nlp, Z) ≈ 0.22766546346850902 atol=1e-6       # POINTS = 3\n",
    "        devals = @dynamicsevals eval_f(nlp, Z)\n",
    "        @test 200 <= devals <= 201                                 # POINTS = 2\n",
    "    end\n",
    "\n",
    "    @testset \"grad_f\" begin                                        # POINTS = 10\n",
    "        # Test the cost gradient with FiniteDiff\n",
    "        grad = zero(Z)\n",
    "        grad_f!(nlp, grad, Z)\n",
    "        devals = @dynamicsevals grad_f!(nlp, grad, Z)\n",
    "        jevals = @jacobianevals grad_f!(nlp, grad, Z)\n",
    "        @test 200 <= devals <= 201                                 # POINTS = 2\n",
    "        @test 200 <= jevals <= 201                                 # POINTS = 2\n",
    "        \n",
    "        grad_fd = FiniteDiff.finite_difference_gradient(x->eval_f(nlp, x), Z)\n",
    "        @test norm(grad - grad_fd) < 1e-8                          # POINTS = 6\n",
    "    end    \n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (b): Evaluate the Constraints (20 pts)\n",
    "Next, we need to define functions to evaluate our constraints. We should have `n + (N-1) n + n` constraints, since we have an initial and goal state, and `(N-1)` dynamics constraints of size `n`, where `n` is the size of our state vector (4).\n",
    "The vector should be stacked as follows:\n",
    "\n",
    "$$ \\begin{bmatrix}\n",
    "x_1 - x_\\text{init} \\\\\n",
    "\\frac{h}{6}(f(x_1, u_1, t_1) + 4 f(x_m, u_m, t_m) + f(x_2, u_2, t_2) + x_1 - x_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{h}{6}(f(x_{N-1}, u_{N-1}, t_{N-1}) + 4 f(x_m, u_m, t_m) + f(x_N, u_N, t_N) + x_{N-1} - x_N \\\\\n",
    "x_N - x_\\text{goal}\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "**TASK**: Complete the following functions defined in the file included in the cell below:\n",
    "- eval_c!(nlp, c, Z)\n",
    "- jac_c!(nlp, jac, Z)\n",
    "\n",
    "As with the cost functions, you will be graded on how many dynamics function evaluations you use. You should only need $N + (N-1)$ dynamics evaluations for the \n",
    "constraints and $N + (N-1)$ dynamics Jacobian evaluations for the constraint Jacobian.\n",
    "\n",
    "You are **NOT** allowed to use finite differencing or automatic differentiation in this function. Not only should you be familiar with how to apply the chain rule to get the pieces you need analytically, we already use ForwardDiff to get the dynamics Jacobians, and nesting calls to ForwardDiff usually results in poor performance.\n",
    "\n",
    "**TIPS**: \n",
    "- Don't worry about the number of dynamics / Jacobian evaluations to begin with. Do something that works, then worry about \"performance.\"\n",
    "- Consider writing some helper functions to evaluate all the pieces you need before the loop. These will probably be the same as the ones you needed for the cost functions.\n",
    "- Write out the derivatives you need by hand using the chain rule. Cache the individual pieces of the chain rule you need and then multiply them together to get the final \n",
    "Jacobians.\n",
    "- Check intermediate Jacobians (e.g. the Jacobians for a single dynamics constraint) with ForwardDiff or FiniteDiff to make sure you've applied the chain rule correctly, then apply it in a loop.\n",
    "\n",
    "The docstrings for these functions are printed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"q2_constraints.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?eval_c!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?jac_c!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"Q2b\" begin                                              # POINTS = 20\n",
    "    prob = CartpoleProblem()\n",
    "    nlp = NLP(prob)\n",
    "    X,U = get_initial_trajectory(prob) \n",
    "    Z = packZ(nlp, X, U)\n",
    "\n",
    "    resfile = joinpath(@__DIR__, \"Q2.jld2\")\n",
    "\n",
    "    @testset \"eval_c\" begin                                      # POINTS = 8\n",
    "        # Constraint function\n",
    "        c = zeros(num_duals(nlp))\n",
    "        devals = @dynamicsevals eval_c!(nlp, c, Z)\n",
    "        @test 200 <= devals <= 201                               # POINTS = 2\n",
    "\n",
    "        @test norm(c - load(resfile, \"c0\")) < 1e-8               # POINTS = 6\n",
    "    end\n",
    "    \n",
    "\n",
    "    @testset \"jac_c\" begin                                       # POINTS = 12 \n",
    "        # Calc constraint Jacobian and check Jacobian evals\n",
    "        jac = zeros(num_duals(nlp), num_primals(nlp)) * NaN\n",
    "        jevals = @jacobianevals jac_c!(nlp, jac, Z)\n",
    "        devals = @dynamicsevals jac_c!(nlp, jac, Z)\n",
    "        @test devals == 0                                        # POINTS = 1\n",
    "        @test 200 <= jevals <= 201                               # POINTS = 4\n",
    "\n",
    "        # Check constraint Jacobian with FiniteDiff\n",
    "        jac_fd = zero(jac)\n",
    "        FiniteDiff.finite_difference_jacobian!(jac_fd, (y,x)->eval_c!(nlp, y, x), Z)\n",
    "        @test norm(jac - jac_fd) < 1e-6                          # POINTS = 7\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c): Solving the NLP (5 pts)\n",
    "Now that we have the methods we need to evaluate our NLP, we can solve it with Ipopt. \n",
    "We use [`MathOptInterface.jl`](https://github.com/jump-dev/MathOptInterface.jl) to interface with the Ipopt solver. Don't worry too much about this interface: we take care of all of the boilerplate code in the file below.\n",
    "\n",
    "You don't need to do anything for this part: if you all of your methods above are correct, your problem should converge in about 30 iterations. If your problem isn't converging, go check your methods above. Remember, the tests aren't perfect and won't catch all of your mistakes. Debugging these types of solvers is a critical skill that takes practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"q2_moi.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = CartpoleProblem()\n",
    "X,U = get_initial_trajectory(prob)\n",
    "nlp = NLP(prob)\n",
    "Z0 = packZ(nlp, X, U)\n",
    "Zsol,solver = solve(Z0, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isautograder || render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let X = [Zsol[xi] for xi in nlp.xinds]\n",
    "    isautograder || visualize!(vis, prob.model, prob.tf, X)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"Q2c\" begin                                     # POINTS = 5\n",
    "    Z = copy(Zsol)\n",
    "    λ = MOI.get(solver, MOI.NLPBlockDual()) # get the duals\n",
    "    X,U = unpackZ(nlp, Zsol)\n",
    "    @test norm(X[1] - prob.x0) < 1e-6                    # POINTS = 0.5\n",
    "    @test norm(X[end] - prob.xf) < 1e-6                  # POINTS = 0.5\n",
    "    grad = zeros(num_primals(nlp)) * NaN\n",
    "    grad_f!(nlp, grad, Z)\n",
    "    c = zeros(num_duals(nlp)) * NaN\n",
    "    eval_c!(nlp, c, Z)\n",
    "    jac = spzeros(num_duals(nlp), num_primals(nlp)) * NaN\n",
    "    jac_c!(nlp, jac, Z)\n",
    "    @test norm(grad - jac'λ, Inf) < 1e-6                 # POINTS = 2\n",
    "    @test norm(c, Inf) < 1e-6                            # POINTS = 2\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (d): Track the solution with model error (10 pts)\n",
    "Let's now use our trajectory and simulate it on a system with some model mismatch.\n",
    "\n",
    "**TASK**:\n",
    "1. Generate controller that tracks your optimized trajectories.\n",
    "2. Run your controller on a simulated cartpole with a cart mass of 1.5 kg instead of 1 kg. Get it to successfully stabilize. The final stabilized position doesn't have to to be at an x-position of 0. Simulate for at least 10 seconds.\n",
    "\n",
    "**TIPS**:\n",
    "1. Feel free to use code from previous homeworks. \n",
    "2. It will stabilize with TVLQR\n",
    "3. If your cartpole gets it to the top but doesn't stabilize it for the full 10 seconds, think about how you could design your controller to stabilize it about the unstable equilibrium..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"q2_controller.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?gen_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isautograder || render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate with a different model\n",
    "let Zref = copy(Zsol)\n",
    "    ctrl = gen_controller(nlp, Zref)\n",
    "    model2 = RobotZoo.Cartpole(1.1, 0.2, 0.5, 9.81)\n",
    "    Xsim, Usim, tsim = simulate(model2, nlp.x0, ctrl, tf=5nlp.tf, dt=0.005)\n",
    "    isautograder || visualize!(vis, model2, tsim[end], Xsim)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "using Random\n",
    "@testset \"Q2d\" begin                                                # POINTS = 10\n",
    "    Random.seed!(1)\n",
    "    model2 = RobotZoo.Cartpole(1.1, 0.2, 0.5, 9.81)\n",
    "    ctrl = gen_controller(nlp, Zsol)\n",
    "    tsim = @elapsed Xsim, Usim, tsim = \n",
    "        simulate(model2, nlp.x0, ctrl, tf=5nlp.tf, dt=0.005)\n",
    "    \n",
    "    # Test real-time performance\n",
    "    @test tsim < 5nlp.tf                                            # POINTS = 1\n",
    "    \n",
    "    # Check that it gets to the goal\n",
    "    @test abs(Xsim[end][1]) < 0.1                                   # POINTS = 0.5\n",
    "    @test abs(Xsim[end][2] - pi) < 1e-2                             # POINTS = 7\n",
    "    @test abs(Xsim[end][3]) < 0.1                                   # POINTS = 0.5\n",
    "    @test abs(Xsim[end][4]) < 1e-2                                  # POINTS = 0.5\n",
    "    @test norm(Usim[end-10:end], Inf) < 0.3                         # POINTS = 0.5\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (e): EXTRA CREDIT Leveraging sparsity (max 5 pts)\n",
    "NLP solvers like Ipopt or SNOPT are designed to leverage sparsity in the problem, especially in the constraint Jacobian. Right now we're ignoring the sparsity structure in the constraint Jacobian, so the solver iterations are fairly slow. Get up to 5 extra credit points by leveraging the sparsity structure in the constraint Jacobian. You'll need to read up on how to specify the sparsity pattern in the [MathOptInterface.jl documentation](http://jump.dev/MathOptInterface.jl/stable/reference/nonlinear/). You should only leverage the sparsity when the `use_sparse_jacobian` flag in the `NLP` struct is set to true. We use this flag to compare the solutions between the normal (dense) version and your sparse version. You'll get points for having matching Jacobians, the size of the nonzeros vector you're passing to Ipopt (shoot for a sparsity of less than 2-5%). You'll also get up to 2 points for the speedup you get from the solver (the TA solution got a speed up of about 100x).\n",
    "\n",
    "**TIPS**\n",
    "- You'll need to modify the `MOI.jacobian_structure` method in `q2_moi.jl`\n",
    "- You'll need to modify the `jac_c!` method that takes a vector in `q2_constraints.jl`\n",
    "\n",
    "We will run the following function to calculate your extra credit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"q2_tests.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isautograder && println(\"Running extra credit\")\n",
    "extra_credit_points = test_extracredit()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
