{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.activate(joinpath(@__DIR__,\"..\")); \n",
    "using ForwardDiff\n",
    "using Test\n",
    "using RobotZoo\n",
    "using RobotDynamics\n",
    "using LinearAlgebra\n",
    "using StaticArrays\n",
    "using SparseArrays\n",
    "using Printf\n",
    "using MeshCat\n",
    "using Plots\n",
    "\n",
    "include(\"quadratic_cost.jl\")\n",
    "include(\"../test/nlp_test.jl\")\n",
    "include(\"cartpole.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Sequential Quadratic Programming (SQP) (50 pts)\n",
    "In this problem you'll solve the canonical cartpole swing-up problem using sequential-quadratic programming (SQP), as we learned in class. While coding up a complete SQP solver is very challenging, we'll simplify it by only considering problems of the form:\n",
    "\n",
    "$$\\begin{aligned} &\\text{minimize}_z && \\frac{1}{2} z^T Q z + q^T z \\\\\n",
    "&\\text{subject to} && c(z) = 0 \\end{aligned} $$\n",
    "\n",
    "I.e. we'll only have you worry about equality constraints. Your overall algorithm should run something like this:\n",
    "1. Initialization\n",
    "2. Build the QP for the current step by taking Taylor series approximations of the cost and constraints\n",
    "3. Solve the QP to get search directions for you primal and dual variables\n",
    "4. Use a line search (or other globalization strategy) to find a good step\n",
    "5. If termination conditions are satisfied, exit; otherwise, go to 2\n",
    "\n",
    "## The Problem\n",
    "You likely have already seen the cartpole swing-up problem previously. As shown in the picture below, the system is comprised of a pendulum attached to a cart, where forces can only be applied to the cart. The goal is to balance the pendulum above the cart. The system dynamics can be written as:\n",
    "\n",
    "$$ x = \\begin{bmatrix} y \\\\ \\theta \\\\ v \\\\ \\omega \\end{bmatrix}, \\quad \\dot{x} = \\begin{bmatrix} \\dot{q} \\\\ \\ddot{q} \\end{bmatrix}, \\quad\n",
    "q = \\begin{bmatrix} y \\\\ \\theta \\end{bmatrix}, \\quad\n",
    "\\ddot{q} = -H^{-1} (C \\dot{q} + G - B u)$$\n",
    "\n",
    "where \n",
    "$$ H = \\begin{bmatrix} m_c + m_p & m_p l \\cos{\\theta} \\\\\n",
    "m_p l \\cos{\\theta} & m_p l^2 \\end{bmatrix}, \\;\n",
    "C = \\begin{bmatrix} 0 & -m_p \\omega l \\sin{\\theta} \\\\ 0 & 0 \\end{bmatrix}, \\;\n",
    "G = \\begin{bmatrix} 0 \\\\ m_p g l \\sin{\\theta} \\end{bmatrix}, \\;\n",
    "B = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} $$\n",
    "\n",
    "with the following parameters:\n",
    "* $m_p$: mass of the pole\n",
    "* $m_c$: mass of the cart\n",
    "* $g$: gravity\n",
    "* $l$: length of the rod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the problem\n",
    "model = RobotZoo.Cartpole()\n",
    "n,m = size(model)\n",
    "T = 101\n",
    "tf = 2.0\n",
    "dt = tf / (T-1)\n",
    "\n",
    "# Initial & final condition\n",
    "x0 = @SVector zeros(n)\n",
    "xf = SA[0,pi,0,0];\n",
    "\n",
    "# Cost function\n",
    "Q = Diagonal(fill(1e-2,n))\n",
    "R = Diagonal(fill(1e-1,m))\n",
    "Qf = Diagonal(fill(1e1,n))\n",
    "costfun = LQRCost(Q,R,xf)\n",
    "costterm = LQRCost(Qf,R,xf)\n",
    "obj = push!(fill(costfun,T-1), costterm)\n",
    "\n",
    "# Initial Guess (linear interpolation)\n",
    "X = [x0 + (xf - x0)*t for t in range(0,1, length=T)]\n",
    "U = [@SVector zeros(m) for k = 1:T-1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a): Evaluate the NLP (14 pts)\n",
    "Before we put together our SQP method, let's write some convenient methods for evaluating the information we'll need from the NLP. We've given you a struct `NLP` below that contains all the information you'll need to evaluate things like the cost function, constraints, and their derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    NLP{n,m,L,Q}\n",
    "\n",
    "Represents a (N)on(L)inear (P)rogram of a trajectory optimization problem,\n",
    "with a dynamics model of type `L`, a quadratic cost function, horizon `T`, \n",
    "and initial and final state `x0`, `xf`.\n",
    "\n",
    "The kth state and control can be extracted from the concatenated state vector `Z` using\n",
    "`Z[nlp.xinds[k]]`, and `Z[nlp.uinds[k]]`.\n",
    "\n",
    "# Constructor\n",
    "    NLP(model, obj, tf, T, x0, xf, [integration])\n",
    "\n",
    "# Basic Methods\n",
    "    Base.size(nlp)    # returns (n,m,T)\n",
    "    num_ineq(nlp)     # number of inequality constraints\n",
    "    num_eq(nlp)       # number of equality constraints\n",
    "    num_primals(nlp)  # number of primal variables\n",
    "    num_duals(nlp)    # total number of dual variables\n",
    "    packZ(nlp, X, U)  # Stacks state `X` and controls `U` into one vector `Z`\n",
    "\n",
    "# Evaluating the NLP\n",
    "The NLP supports the following API for evaluating various pieces of the NLP:\n",
    "\n",
    "    eval_f(nlp, Z)         # evaluate the objective\n",
    "    grad_f!(nlp, grad, Z)  # gradient of the objective\n",
    "    hess_f!(nlp, hess, Z)  # Hessian of the objective\n",
    "    eval_c!(nlp, c, Z)     # evaluate the constraints\n",
    "    jac_c!(nlp, c, Z)      # constraint Jacobian\n",
    "\"\"\"\n",
    "struct NLP{n,m,L,Q}\n",
    "    model::L                                 # dynamics model\n",
    "    obj::Vector{QuadraticCost{n,m,Float64}}  # objective function\n",
    "    T::Int                                   # number of knot points\n",
    "    tf::Float64                              # total time (sec)\n",
    "    x0::MVector{n,Float64}                   # initial condition\n",
    "    xf::MVector{n,Float64}                   # final condition\n",
    "    xinds::Vector{SVector{n,Int}}            # Z[xinds[k]] gives states for time step k\n",
    "    uinds::Vector{SVector{m,Int}}            # Z[uinds[k]] gives controls for time step k\n",
    "    times::Vector{Float64}                   # vector of times\n",
    "    function NLP(model::AbstractModel, obj::Vector{<:QuadraticCost{n,m}},\n",
    "            tf::Real, T::Integer, x0::AbstractVector, xf::AbstractVector, integration::Type{<:QuadratureRule}=RK4\n",
    "        ) where {n,m}\n",
    "        xinds = [SVector{n}((k-1)*(n+m) .+ (1:n)) for k = 1:T]\n",
    "        uinds = [SVector{m}((k-1)*(n+m) .+ (n+1:n+m)) for k = 1:T-1]\n",
    "        times = collect(range(0, tf, length=T))\n",
    "        new{n,m,typeof(model), integration}(\n",
    "            model, obj,\n",
    "            T, tf, x0, xf, xinds, uinds, times\n",
    "        )\n",
    "    end\n",
    "end\n",
    "Base.size(nlp::NLP{n,m}) where {n,m} = (n,m,nlp.T)\n",
    "num_primals(nlp::NLP{n,m}) where {n,m} = n*nlp.T + m*(nlp.T-1)\n",
    "num_duals(nlp::NLP) = num_eq(nlp) + num_ineq(nlp)\n",
    "num_eq(nlp::NLP{n,m}) where {n,m} = n*nlp.T + n\n",
    "num_ineq(nlp::NLP) = 0\n",
    "\n",
    "\"\"\"\n",
    "    packZ(nlp, X, U)\n",
    "\n",
    "Take a vector state vectors `X` and controls `U` and stack them into a single vector Z.\n",
    "\"\"\"\n",
    "function packZ(nlp, X, U)\n",
    "    Z = zeros(num_primals(nlp))\n",
    "    for k = 1:nlp.T-1\n",
    "        Z[nlp.xinds[k]] = X[k]\n",
    "        Z[nlp.uinds[k]] = U[k]\n",
    "    end\n",
    "    Z[nlp.xinds[end]] = X[end]\n",
    "    return Z\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    unpackZ(nlp, Z)\n",
    "\n",
    "Take a vector of all the states and controls and return a vector of state vectors `X` and\n",
    "controls `U`.\n",
    "\"\"\"\n",
    "function unpackZ(nlp, Z)\n",
    "    X = [Z[xi] for xi in nlp.xinds]\n",
    "    U = [Z[ui] for ui in nlp.uinds]\n",
    "    return X, U\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Examples\n",
    "You may find the following code snippets helpful as you complete the methods for the NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NLP\n",
    "nlp = NLP(model, obj, tf, T, x0, xf)\n",
    "\n",
    "# Create a vector of all states and controls\n",
    "Z = packZ(nlp, X, U)\n",
    "\n",
    "# Unpack into states and vectors\n",
    "X2, U2 = unpackZ(nlp, Z)\n",
    "\n",
    "# Evaluate the cost\n",
    "cost(nlp.obj, X, U)\n",
    "\n",
    "# Get kth state, control\n",
    "k = 10\n",
    "x = Z[nlp.xinds[k]]\n",
    "u = Z[nlp.uinds[k]]\n",
    "\n",
    "# Dynamics\n",
    "t = nlp.times[k]\n",
    "dt = nlp.times[k+1] - nlp.times[k[]]\n",
    "discrete_dynamics(RK4, nlp.model, x, u, t, dt)\n",
    "\n",
    "# Dynamics Jacobian\n",
    "∇f = zeros(n,n+m)\n",
    "discrete_jacobian!(RK4, ∇f, nlp.model, x, u, t, dt)\n",
    "\n",
    "# 2nd-order Dynamics derivative\n",
    "#   derivative of ∇f'b\n",
    "∇jac = zeros(n+m,n+m)\n",
    "b = zeros(n)\n",
    "∇discrete_jacobian!(RK4, ∇jac, nlp.model, x, u, t, dt, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "Complete the following methods to evaluate the objective and its derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Finish the following methods\n",
    "#       eval_f  (2 pts)\n",
    "#       grad_f! (2 pts)\n",
    "#       hess_f! (2 pts)\n",
    "\n",
    "\"\"\"\n",
    "    eval_f(nlp, Z)\n",
    "\n",
    "Evaluate the objective, returning a scalar.\n",
    "\"\"\"\n",
    "function eval_f(nlp::NLP, Z)\n",
    "    # TODO: compute the objective value (cost)\n",
    "    J = 0.0\n",
    "    return J\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    grad_f!(nlp, grad, Z)\n",
    "\n",
    "Evaluate the gradient of the objective at `Z`, storing the result in `grad`.\n",
    "\"\"\"\n",
    "function grad_f!(nlp::NLP{n,m}, grad, Z) where {n,m}\n",
    "    xi,ui = nlp.xinds, nlp.uinds\n",
    "    obj = nlp.obj\n",
    "    for k = 1:nlp.T-1\n",
    "        x,u = Z[xi[k]], Z[ui[k]]\n",
    "        # TODO: Compute the cost gradient\n",
    "        grad[xi[k]] .= 0\n",
    "        grad[ui[k]] .= 0\n",
    "    end\n",
    "    grad[xi[end]] = obj[end].Q*Z[xi[end]] + obj[end].q\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    hess_f!(nlp, hess, Z)\n",
    "\n",
    "Evaluate the Hessian of the objective at `Z`, storing the result in `hess`.\n",
    "Should work with `hess` sparse.\n",
    "\"\"\"\n",
    "function hess_f!(nlp::NLP{n,m}, hess, Z, rezero=true) where {n,m}\n",
    "    # TODO: Compute the objective hessian\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints\n",
    "Complete the following methods to evaluate the constraints and their derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Complete the following methods\n",
    "#       eval_c!  (2 pts)\n",
    "#       jac_c!   (2 pts)\n",
    "#       ∇jvp!    (2 pts)\n",
    "\"\"\"\n",
    "    eval_c!(nlp, c, Z)\n",
    "\n",
    "Evaluate the equality constraints at `Z`, storing the result in `c`.\n",
    "The constraints should be ordered as follows: \n",
    "1. Initial condition ``x_1 = x_\\\\text{init}``\n",
    "2. Dynamics ``f(x_k,u_k) - x_{k+1} = 0``\n",
    "3. Terminal constraint ``x_T = x_\\\\text{goal}``\n",
    "\"\"\"\n",
    "function eval_c!(nlp::NLP{n,m,<:Any,Q}, c, Z) where {n,m,Q}\n",
    "    T = nlp.T\n",
    "    xi,ui = nlp.xinds, nlp.uinds\n",
    "    idx = xi[1]\n",
    "\n",
    "    # TODO: initial condition\n",
    "\n",
    "    # dynamics\n",
    "    for k = 1:T-1\n",
    "        idx = idx .+ n\n",
    "        x,u = Z[xi[k]], Z[ui[k]]\n",
    "        x⁺ = Z[xi[k+1]]\n",
    "        dt = nlp.times[k+1] - nlp.times[k]\n",
    "        \n",
    "        # TODO: Dynamics constraint\n",
    "        c[idx] .= 0\n",
    "        \n",
    "    end\n",
    "\n",
    "    # TODO: terminal constraint\n",
    "    idx = idx .+ n\n",
    "    c[idx] .= 0\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    jac_c!(nlp, jac, Z)\n",
    "\n",
    "Evaluate the constraint Jacobian, storing the result in the (potentially sparse) matrix `jac`.\n",
    "\"\"\"\n",
    "function jac_c!(nlp::NLP{n,m,<:Any,Q}, jac, Z) where {n,m,Q}\n",
    "    # TODO: Initial condition\n",
    "\n",
    "    xi,ui = nlp.xinds, nlp.uinds\n",
    "    idx = xi[1]\n",
    "    for k = 1:nlp.T-1\n",
    "        idx = idx .+ n \n",
    "        zi = [xi[k];ui[k]]\n",
    "        zi2 = k < T-1 ? zi .+ (n+m) : xi[T]\n",
    "        x = Z[xi[k]]\n",
    "        u = Z[ui[k]]\n",
    "        t = nlp.times[k]\n",
    "        dt = nlp.times[k+1] - nlp.times[k]\n",
    "\n",
    "        ∇f = view(jac, idx, zi)\n",
    "        ∇f2 = view(jac, idx, zi2)\n",
    "        \n",
    "        # TODO: Dynamics constraint\n",
    "    end\n",
    "    idx = idx .+ n \n",
    "    \n",
    "    # TODO: Terminal constraint\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lagrangian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Complete the following methods\n",
    "#       lagrangian         (2 pts)\n",
    "#       grad_lagrangian!   (2 pts)\n",
    "\n",
    "\"\"\"\n",
    "    lagrangian(nlp, Z, λ, c)\n",
    "\n",
    "Evaluate the Lagrangian at `Z` and `λ`. Calculates the constraints, storing the result in `c`.\n",
    "\n",
    "The sign on the multipliers should be negative, e.g. J(x) - λ'c(x)\n",
    "\"\"\"\n",
    "function lagrangian(nlp::NLP{n,m}, Z, λ, c=zeros(eltype(Z),length(λ))) where {n,m}\n",
    "    # TODO: Calculate the Lagrangian\n",
    "    L = 0\n",
    "    return L\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    grad_lagrangian(nlp, grad, Z, λ)\n",
    "\n",
    "Evaluate the gradient of the Lagrangian.\n",
    "\"\"\"\n",
    "function grad_lagrangian!(nlp::NLP{n,m}, grad, Z, λ, jac = spzeros(length(λ), length(Z))) where {n,m}\n",
    "    # TODO: Calculate the gradient of the Lagrangian, store the result in grad\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residuals\n",
    "Feel free to use these function to evaluate the primal and dual residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    primal_residual(nlp, Z, λ, [g; p])\n",
    "\n",
    "Evaluate the `p`-norm of the primal residual (stationarity condition).\n",
    "\"\"\"\n",
    "function primal_residual(nlp::NLP, Z, λ, g=zeros(num_primals(nlp)); p=2)\n",
    "    grad_lagrangian!(nlp, g, Z, λ)\n",
    "    return norm(g, p)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    dual_residual(nlp, Z, λ, [c; p])\n",
    "\n",
    "Evaluate the `p`-norm of the dual residual (constraint violation).\n",
    "\"\"\"\n",
    "function dual_residual(nlp::NLP, Z, λ, c=zeros(num_eq(nlp)); p=2)\n",
    "    eval_c!(nlp, c, Z)\n",
    "    norm(c, p)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = NLP(model, obj, tf, T, x0, xf)\n",
    "Z = packZ(nlp, X, U)\n",
    "λ = zeros(num_duals(nlp));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../test/nlp_test.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test methods\n",
    "test_nlp(nlp, Z, λ);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b): Solving the QP (8 pts)\n",
    "Now that we have methods to evaluate our NLP and its derivatives, we need some methods to form the QP from our NLP and then solve it. Use the struct we've provided below and implement the `build_qp!` method to update the QP sub-problem from the current primal and dual variables, as well as the `solve_qp!` method to solve it for the step directions in the primal and dual variables. Note that since our NLP only has equality constraints, the QP sub-problem will also only have equality constraints, so it can be solved directly using a linear solve on the KKT conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@doc raw\"\"\"\n",
    "    TOQP\n",
    "\n",
    "A type specifying a (T)rajectory (O)ptimization (Q)uadratic (P)rogram, of the form\n",
    "\n",
    "\n",
    "``\\begin{aligned} &\\text{minimize} &&\\frac{1}{2} z^T Q z + q^T z \\\\ \n",
    "&\\text{subject to} && A z = b \\\\ \n",
    "&&& l \\leq C z \\leq u \\end{aligned}``\n",
    "\n",
    "where ``z = [x_1^T \\; u_1^T \\; \\dots \\; x_{T-1}^T \\; u_{T-1}^T \\; x_T^T]^T`` and \n",
    "``x \\in \\mathbb{R}^n`` is the state vector and ``u \\in \\mathbb{R}^m`` is the control vector.\n",
    "\n",
    "# Constructors\n",
    "\n",
    "    TOQP(n,m,T,M,P)\n",
    "\n",
    "where `n` is the number of states, `m` is the number of controls, `T` is the horizon, `M` is the number of equality \n",
    "constraints, and `P` is the number of inequality constraints.\n",
    "\n",
    "# Methods\n",
    "\n",
    "    num_ineq(qp)     # number of inequality constraints\n",
    "    num_eq(qp)       # number of equality constraints\n",
    "    num_primals(qp)  # number of primal variables\n",
    "    num_duals(qp)    # total number of dual variables\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "struct TOQP\n",
    "    Q::SparseMatrixCSC{Float64,Int}  # quadratic cost\n",
    "    q::Vector{Float64}               # linear cost\n",
    "    A::SparseMatrixCSC{Float64,Int}  # equality constraint Ax = b\n",
    "    b::Vector{Float64}               # equality constraint \n",
    "    C::SparseMatrixCSC{Float64,Int}  # inequality constraint l ≤ Cx ≤ u\n",
    "    l::Vector{Float64}               # inequality constraint lower bound\n",
    "    u::Vector{Float64}               # inequality constraint upper bound\n",
    "    n::Int\n",
    "    m::Int\n",
    "    T::Int\n",
    "\n",
    "    function TOQP(n,m,T,M,P)\n",
    "        N = n*T + (T-1)*m\n",
    "        Q = spzeros(N,N)\n",
    "        q = zeros(N)\n",
    "        A = spzeros(M,N)\n",
    "        b = zeros(M) \n",
    "        C = spzeros(P,N)\n",
    "        l = fill(-Inf,P)\n",
    "        u = fill(Inf,P)\n",
    "\n",
    "        new(Q,q,A,b,C,l,u,n,m,T)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function TOQP(nlp::NLP{n,m}) where {n,m}\n",
    "    TOQP(n,m,nlp.T, num_eq(nlp), num_ineq(nlp))\n",
    "end\n",
    "\n",
    "num_ineq(qp::TOQP) = length(qp.l)\n",
    "num_eq(qp::TOQP) = length(qp.b)\n",
    "num_primals(qp::TOQP) = length(qp.q)\n",
    "num_duals(qp::TOQP) = num_ineq(qp) + num_eq(qp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the QP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Complete the following method to build the QP sub-problem (3 pts)\n",
    "\"\"\"\n",
    "    build_qp!(qp, nlp, Z, λ; [gn=true])\n",
    "\n",
    "Build a QP from the NLP, evaluated at primal variables `Z` and dual variables `λ`, \n",
    "optionally using either the Hessian of the cost function (`gn = true`) or the Hessian of the Lagrangian (`gn = false`).\n",
    "\"\"\"\n",
    "function build_qp!(qp::TOQP, nlp::NLP, Z, λ; gn::Bool=true)\n",
    "    # TODO: Build the qp, filling in qp.Q, qp.q, qp.A, qp.b\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the QP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Complete the function to solve the QP (5 pts)\n",
    "\"\"\"\n",
    "    solve_qp!(qp, [reg])\n",
    "\n",
    "Solve the QP, optionally applying regularization `reg`.\n",
    "\"\"\"\n",
    "function solve_qp!(qp::TOQP, reg=0.0)\n",
    "    # TODO: Solve the QP sub-problem\n",
    "    # HINT: Form the KKT system and solve with a single linear solve\n",
    "    N,M = num_primals(qp), num_duals(qp)\n",
    "    dZ = zeros(N)\n",
    "    dλ = zeros(M)\n",
    "    return dZ, dλ\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c): Writing the SQP Method (15 pts)\n",
    "Now that you have all the pieces, put them all together into an SQP method. We provide some more details about the line search we reccommend you implement below.\n",
    "\n",
    "### Line Search\n",
    "For SQP, we reccommend using the \"exact\" $\\ell_1$ merit function:\n",
    "\n",
    "$$ \\phi_1(x; \\mu) = f(x) + \\mu ||c(x)||_1 $$\n",
    "\n",
    "whose directional derivative in direction $p_k$ can be computed using:\n",
    "\n",
    "$$ D\\left(\\phi_1(x_k; \\mu); p_k\\right) = \\nabla f_k^T p_k - \\mu ||c_k||_1 $$\n",
    "\n",
    "The penalty parameter $\\mu$ should always have a value greater than or equal to this expression:\n",
    "\n",
    "$$ \\mu \\geq \\frac{\\nabla f_k^T p_k + (\\sigma/2) p_k^T \\nabla_{xx}^2 \\mathcal{L}_k p_k}{(1-\\rho) ||c_k||_1} $$\n",
    "\n",
    "where $\\rho = 0.5$, and\n",
    "\n",
    "$$ \\sigma = \\begin{cases} 1 & \\text{if } p_k^T \\nabla_{xx}^2 \\mathcal{L}_k p_k > 0 \\\\\n",
    "0 & \\text{otherwise} \\end{cases} $$.\n",
    "\n",
    "Here $p_k$ is the step direction, $\\nabla f_k$ is the gradient of the cost function at the current value of $x$, $c_k$ are the constraint values at the current value of $x$, and $\\nabla_{xx}^2 \\mathcal{L}_k$ is the Hessian of the Lagrangian for the current value of $x$. For more information, see Nocedal and Wright Ch 18.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solve_sqp"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK: Complete the SQP method (15 pts)\n",
    "\"\"\"\n",
    "    solve_sqp(nlp, Z, λ; kwargs...)\n",
    "\n",
    "Solve the trajectory optimization problem specified by `nlp` using Sequential Quadratic Programming, given the initial \n",
    "guess for the primal variables `Z` and `λ`.\n",
    "\"\"\"\n",
    "function solve_sqp(nlp, Z0, λ0;\n",
    "        iters=100,                   # max number of iterations\n",
    "        verbose=0,                   # verbosity level\n",
    "        eps_primal=1e-6,             # primal feasibility tolerance\n",
    "        eps_dual=1e-4,               # dual feasibility tolerance\n",
    "        eps_fn=sqrt(eps_primal),     # \n",
    "        gn::Bool=true,               # use Gauss-Newton approximation\n",
    "        enable_soc::Bool=true,       # enable Second-Order-Corrections during the line search\n",
    "        ls_iters=10,                 # max number of line search iterations\n",
    "        reg_min=1e-6,                # minimum regularization\n",
    "    )\n",
    "    t_start = time_ns()\n",
    "\n",
    "    # Initialize solution\n",
    "    Z = deepcopy(Z0)\n",
    "    λ = deepcopy(λ0)\n",
    "    qp = TOQP(nlp)\n",
    "\n",
    "    # Line Search parameters\n",
    "    μ = 10.0                         # initial merit function penalty\n",
    "    reg = reg_min                    # regularization\n",
    "\n",
    "    # Stats\n",
    "    # TODO: Fill this is during your solve\n",
    "    stats = Dict(\n",
    "        :cost => Float64[],\n",
    "        :viol_primal => Float64[],  # constraint violation\n",
    "        :viol_dual => Float64[],    # stationarity\n",
    "        :time => Float64[]\n",
    "    )\n",
    "\n",
    "    # Primary Loop\n",
    "    for iter = 1:iters\n",
    "        #### TODO: Check Convergence ####\n",
    "\n",
    "        #### TODO: Build and Solve QP ####\n",
    "        \n",
    "        \n",
    "        #### TODO: Penalty Update ####\n",
    "        \n",
    "\n",
    "        #### TODO: Line Search Initialization ####\n",
    "        \n",
    "        # Params\n",
    "        α = 1.0                                # line search parameter\n",
    "        J0 = eval_f(nlp, Z)                    # initial cost\n",
    "        phi0 = Inf                             # initial merit function value\n",
    "        dphi0 = Inf                            # initial merit function gradient\n",
    "\n",
    "        #### TODO: Backtracking line search ####\n",
    "        \n",
    "        \n",
    "        #### TODO: Apply Step ####\n",
    "\n",
    "        # Output\n",
    "        verbose > 0 && @printf(\"   α = %0.2f, ΔJ: %0.2e, Δϕ: %0.2e, reg: %0.2e, pen: %d\\n\", \n",
    "            α, J - eval_f(nlp, Z), phi0 - phi, reg, μ)\n",
    "        push!(stats[:time], (time_ns() - t_start) / 1e6)  # ms\n",
    "    end\n",
    "    \n",
    "    return Z, λ, stats \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Solve the problem with SQP\n",
    "#       Save the output to Zgn, λgn, stats_gn\n",
    "#       Solve to a tolerance of 1e-6 for constraint satisfaction and 1e-4 for stationarity condition\n",
    "\n",
    "Z = packZ(nlp, X, U)\n",
    "λ = zeros(num_duals(nlp))\n",
    "Zgn, λgn, stats_gn = solve_sqp(nlp, Z, λ, verbose=0, gn=true);\n",
    "length(stats_gn[:time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualizer()\n",
    "set_mesh!(vis, model)\n",
    "render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgn = [Zgn[xi] for xi in nlp.xinds]\n",
    "visualize!(vis, model, tf, Xgn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (d): Implement Full Newton (4 pts)\n",
    "To compute the full Newton step, we need to evaluate the second-order derivatives of our constraints. Complete the methods below to calculate the full 2nd-order expansion of the Lagrangian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Finish the methods below\n",
    "#       ∇jvp!              (2 pts)\n",
    "#       hess_lagrangian!   (2 pts)\n",
    "\n",
    "\"\"\"\n",
    "    ∇jvp!(nlp, hess, Z, λ)\n",
    "\n",
    "Evaluate the Jacobian of the constraint Jacobian-transpose vector product, e.g. ``\\\\frac{\\\\partial}{\\\\partial z} \\\\nabla c^T \\\\lambda``,\n",
    "storing the result in the (potentially sparse) matrix `hess`.\n",
    "\"\"\"\n",
    "function ∇jvp!(nlp::NLP{n,m,<:Any,Q}, hess, Z, λ) where {n,m,Q}\n",
    "    xi,ui = nlp.xinds, nlp.uinds\n",
    "    idx = [xi[1]; ui[1]]\n",
    "    idx2 = xi[1]\n",
    "    \n",
    "    # TODO: Initial Constraint\n",
    "    \n",
    "    # Dynamics constraints\n",
    "    for k = 1:nlp.T-1\n",
    "        idx2 = idx2 .+ n\n",
    "        zi2 = k < T-1 ? idx .+ (n+m) : xi[T]\n",
    "        x = Z[xi[k]]\n",
    "        u = Z[ui[k]]\n",
    "        λk = λ[idx2]\n",
    "        t = nlp.times[k]\n",
    "        dt = nlp.times[k+1] - nlp.times[k]\n",
    "        \n",
    "        ∇f = view(hess, idx, idx)\n",
    "        ∇f2 = view(hess, idx, zi2)\n",
    "        \n",
    "        # TODO: Calculate second derivative the dynamics\n",
    "        \n",
    "        # Advance indices\n",
    "        idx = idx .+ (n + m)\n",
    "    end\n",
    "    # TODO: Terminal constraint\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    hess_lagrangian(nlp, grad, Z, λ)\n",
    "\n",
    "Evaluate the Hessian of the Lagrangian.\n",
    "\"\"\"\n",
    "function hess_lagrangian!(nlp::NLP{n,m}, hess, Z, λ) where {n,m}\n",
    "    # TODO: Calculate the Hessian of the Lagrangian, store the result in hess\n",
    "    return nothing\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the methods\n",
    "test_nlp(nlp, Z, λ, full_newton=true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (e): Solve with Full Newton (2 pts)\n",
    "Now that we can calculate our full Newton step, modify `build_qp!` to use `hess_lagrangian!` when the `gn` is false. Then solve the problem with the full Newton solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Do the following\n",
    "#       1. Modify build_qp! to use the full Newton Hessian when `gn = false`\n",
    "#       2. Solve the problem using full Newton steps. Save the result in Zfn, λfn, stats_fn\n",
    "\n",
    "Z = packZ(nlp, X, U)\n",
    "λ = zeros(num_duals(nlp))\n",
    "Zfn, λfn, stats_fn = solve_sqp(nlp, Z, λ, verbose=0, gn=false, eps_dual=1e-4);\n",
    "length(stats_fn[:time])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (f): Convergence Comparison (2 pts)\n",
    "Let's compare the convergence of Gauss Newton versus Full Newton. Generate the following plots:\n",
    "1. Constraint violation vs iterations. Include a line for both Gauss and Full Newton\n",
    "2. Constraint violation vs time. Include a line for both Gauss and Full Newton\n",
    "\n",
    "Once you've generated the plots, take a minute to think about they tell you. What are the tradeoffs of using Gauss-Newton vs full Newton?\n",
    "\n",
    "You are free to use whatever plotting library you want (we suggest PyPlot.jl or Plots.jl).\n",
    "\n",
    "**TIP**: Save the data you need in the stats dictionary that returned from the sqp solver.\n",
    "\n",
    "**TIP**: If your plot vs time has a large offset before the first iteration, run your solver again (remember it has to compile the first time through)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Plot constraint violation vs iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Plot constraint violation vs time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (g): Track the solution with TVLQR (5 pts)\n",
    "Let's now use our trajectory and simulate it on a system with some model mismatch.\n",
    "\n",
    "**TASK**:\n",
    "1. Generate a TVLQR controller that tracks your optimized trajectories.\n",
    "2. Run your controller on a simulated cartpole with a cart mass of 1.1 kg instead of 1 kg. Get it to successfully stabilize. The final stabilized position doesn't have to to be at an x-position of 0. Simulate for at least 4 seconds.\n",
    "\n",
    "**TIPS**:\n",
    "1. Use code you've generated previously to build your TVLQR controller\n",
    "2. If your cartpole gets it to the top but doesn't stabilize it for the full 4 seconds, think about how you could design your controller to stabilize it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Generate a TVLQR controller\n",
    "#       Store your controller as the variable `ctrl`\n",
    "\n",
    "# TODO: Replace this with a controller of your choice\n",
    "ctrl = NullController(model)\n",
    "\n",
    "# SOLUTION\n",
    "using ControlSystems\n",
    "\n",
    "function tvlqr(A,B,Q,R,Qf)\n",
    "    # Extract some variables\n",
    "    T = length(A)+1\n",
    "    n,m = size(B[1])\n",
    "    P = [zeros(n,n) for k = 1:T]\n",
    "    K = [zeros(m,n) for k = 1:T-1]\n",
    "    \n",
    "    P[end] .= Qf\n",
    "    for k = reverse(1:T-1) \n",
    "        K[k] .= (R + B[k]'P[k+1]*B[k])\\(B[k]'P[k+1]*A[k])\n",
    "        P[k] .= Q + A[k]'P[k+1]*A[k] - A[k]'P[k+1]*B[k]*K[k]\n",
    "    end\n",
    "    \n",
    "    return K,P\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    LQRController\n",
    "\n",
    "A TVLQR controller that tracks the trajectory specified by `Xref` and `Uref`\n",
    "using the linear feedback gains `K`.\n",
    "\"\"\"\n",
    "struct LQRController\n",
    "    K::Vector{Matrix{Float64}}\n",
    "    Xref::Vector{Vector{Float64}}\n",
    "    Uref::Vector{Vector{Float64}}\n",
    "    times::Vector{Float64}\n",
    "end\n",
    "get_k(controller, t) = searchsortedlast(controller.times, t)\n",
    "\n",
    "function get_control(ctrl::LQRController, x, t)\n",
    "    k = get_k(ctrl, t)\n",
    "    K = ctrl.K[k]\n",
    "    return ctrl.Uref[k] - K*(x - ctrl.Xref[k])\n",
    "end\n",
    "\n",
    "# Generate A,B matrices\n",
    "Xfn,Ufn = unpackZ(nlp, Zfn)\n",
    "A = [zeros(n,n) for k = 1:T-1]\n",
    "B = [zeros(n,m) for k = 1:T-1]\n",
    "∇f = RobotDynamics.DynamicsJacobian(model)\n",
    "for k = 1:T-1\n",
    "    local t = nlp.times[k]\n",
    "    local dt = nlp.times[k+1] - nlp.times[k]\n",
    "    discrete_jacobian!(RK4, ∇f, model, Xfn[k], Ufn[k], t, dt)\n",
    "    A[k] .= ∇f.A\n",
    "    B[k] .= ∇f.B\n",
    "end\n",
    "\n",
    "\n",
    "Kinf = dlqr(A[end], B[end], Matrix(Q), Matrix(R))\n",
    "\n",
    "K, = tvlqr(A,B,Q,R,Qf)\n",
    "push!(K,Kinf)\n",
    "push!(Ufn,zeros(m))\n",
    "ctrl = LQRController(K, Xfn, Ufn, nlp.times);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate with a different model\n",
    "model2 = RobotZoo.Cartpole(1.1, 0.2, 0.5, 9.81)\n",
    "Xsim, Usim, tsim = simulate(model2, x0, ctrl, tf=2tf)\n",
    "visualize!(vis, model, tsim[end], Xsim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tests();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
